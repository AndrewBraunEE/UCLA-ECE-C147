{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##4QAM, 16QAM, 64QAM, BPSK, 8PSK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Layer\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers, regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import CuDNNLSTM\n",
    "from keras.layers import MaxPooling1D\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definitions to automatically generate symbols of QAM and M-Ary PSK\n",
    "def gray_code(n):\n",
    "    if n < 1:\n",
    "        g = []\n",
    "    else:\n",
    "        g = ['0', '1']\n",
    "        n -= 1\n",
    "        while n > 0:\n",
    "            k = len(g)\n",
    "            for i in range(k-1, -1, -1):\n",
    "                char = '1' + g[i]\n",
    "                g.append(char)\n",
    "            for i in range(k-1, -1, -1):\n",
    "                g[i] = '0' + g[i]\n",
    "            n -= 1\n",
    "    return g\n",
    "\n",
    "class BasicModem:\n",
    "    def TX(self, payload_data): #String type input\n",
    "        syms_out = np.zeros(int(len(payload_data)/self.bit_num), dtype=np.complex64)\n",
    "        cnt = 0\n",
    "        for i in range(0, len(payload_data) - self.bit_num, self.bit_num):\n",
    "            syms_out[cnt] = self.inv_dict[payload_data[i:i+self.bit_num]]\n",
    "            cnt += 1\n",
    "        return syms_out\n",
    "    \n",
    "    def RX(self, symbol_array): #Hard demodulation, no coding schemes done\n",
    "        index_list = []\n",
    "        \n",
    "        for symbol in symbol_array:\n",
    "            index_list.append(np.argmin(abs(symbol - self.coords)))\n",
    "        output = ''\n",
    "        for i in index_list:\n",
    "            output += self.dict[self.coords[i]]\n",
    "        \n",
    "        return output\n",
    "\n",
    "class QAM(BasicModem):\n",
    "    def __init__(self, NUM_SYMBOLS = 4, SAMP_RATE = 1):\n",
    "        self.NUM_SYMBOLS = NUM_SYMBOLS\n",
    "        self.SAMP_RATE = SAMP_RATE\n",
    "        dim_iq_axis = int(np.sqrt(NUM_SYMBOLS))\n",
    "        self.coords = []\n",
    "        self.symbols = gray_code(np.log2(NUM_SYMBOLS))\n",
    "        MAX_ENERGY = np.sqrt(2) #For QAM with coordinates at (x=1,y=1), normalized energy: divide by sqrt(2)\n",
    "        x = np.linspace(-1, 1, dim_iq_axis, dtype='complex64')\n",
    "        x, y = np.meshgrid(x, x)\n",
    "        self.coords = (x + y * 1j).flatten()\n",
    "        self.dict = dict(zip(self.coords, self.symbols))\n",
    "        self.inv_dict = dict(zip(self.symbols, self.coords))\n",
    "        self.bit_num = int(np.log2(NUM_SYMBOLS))\n",
    "\n",
    "class PSK(BasicModem):\n",
    "    def __init__(self, NUM_SYMBOLS = 8, SAMP_RATE = 1):\n",
    "        self.NUM_SYMBOLS = NUM_SYMBOLS\n",
    "        self.SAMP_RATE = SAMP_RATE\n",
    "        self.coords = np.zeros(NUM_SYMBOLS, dtype='complex64')\n",
    "        self.symbols = gray_code(np.log2(NUM_SYMBOLS))\n",
    "        cnt = 0\n",
    "        for i in np.arange(0, 2*np.pi, 2*np.pi/NUM_SYMBOLS):\n",
    "            #i is the phase\n",
    "            self.coords[cnt] =  1*np.exp(1j*i)\n",
    "            cnt += 1\n",
    "        #Above generates an array with the approximate locations of the symbols.\n",
    "        self.dict = dict(zip(self.coords, self.symbols))\n",
    "        self.inv_dict = dict(zip(self.symbols, self.coords))\n",
    "        self.bit_num = int(np.log2(NUM_SYMBOLS))\n",
    "        print(self.dict)\n",
    "\n",
    "class rayleigh_multipath:\n",
    "    \"\"\" a multipath channel with Rayleigh fading and AWGN \"\"\"\n",
    "    def __init__(self, var_awgn, var_rayleigh, pdp):\n",
    "        self.sigma_awgn = np.sqrt(var_awgn)\n",
    "        self.sigma_rayleigh = np.sqrt(var_rayleigh)\n",
    "        self.pdp = np.array(pdp)\n",
    "        self.l = self.pdp.size-1\n",
    "        self.update_cir()\n",
    "\n",
    "    def update_cir(self):\n",
    "        \"\"\" generate a new CIR from the PDP with Rayleigh fading \"\"\"\n",
    "        self.cir = np.sqrt(np.array(self.pdp))\n",
    "        randray = np.random.rayleigh(self.sigma_rayleigh, self.cir.size)\n",
    "        self.cir = self.cir*randray\n",
    "\n",
    "    def awgn(self, symbols):\n",
    "        \"\"\" add white Gaussian noise \"\"\"\n",
    "        real_noise = np.random.randn(symbols.size)\n",
    "        imag_noise = np.random.randn(symbols.size)\n",
    "        noise = real_noise+1j*imag_noise\n",
    "        return symbols+self.sigma_awgn*noise\n",
    "\n",
    "    def apply_cir(self, symbols):\n",
    "        \"\"\" convolve the symbols with the CIR \"\"\"\n",
    "        if self.l != 0:\n",
    "            self.old_symbols = symbols[-self.l:]\n",
    "        # apply the cir\n",
    "        symbols = np.convolve(symbols, self.cir)\n",
    "        return symbols \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1+0j): '0', (-1+1.2246469e-16j): '1'}\n",
      "{(1+0j): '0000', (0.9238795+0.38268343j): '0001', (0.70710677+0.70710677j): '0011', (0.38268343+0.9238795j): '0010', (6.123234e-17+1j): '0110', (-0.38268343+0.9238795j): '0111', (-0.70710677+0.70710677j): '0101', (-0.9238795+0.38268343j): '0100', (-1+1.2246469e-16j): '1100', (-0.9238795-0.38268343j): '1101', (-0.70710677-0.70710677j): '1111', (-0.38268343-0.9238795j): '1110', (-1.8369701e-16-1j): '1010', (0.38268343-0.9238795j): '1011', (0.70710677-0.70710677j): '1001', (0.9238795-0.38268343j): '1000'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.+1.j, 1.-1.j, 0.+0.j], dtype=complex64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myqam4 = QAM(NUM_SYMBOLS=4)\n",
    "myqam16 = QAM(NUM_SYMBOLS=16)\n",
    "myqam64 = QAM(NUM_SYMBOLS=64)\n",
    "myBPSK = PSK(NUM_SYMBOLS = 2)\n",
    "myPSK8 = PSK(NUM_SYMBOLS = 16)\n",
    "myqam4.TX('100100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors: CommPy contributors\n",
    "# License: BSD 3-Clause\n",
    "\n",
    "\"\"\"\n",
    "==================================================\n",
    "Modulation Demodulation (:mod:`commpy.modulation`)\n",
    "==================================================\n",
    ".. autosummary::\n",
    "   :toctree: generated/\n",
    "   PSKModem             -- Phase Shift Keying (PSK) Modem.\n",
    "   QAMModem             -- Quadrature Amplitude Modulation (QAM) Modem.\n",
    "   ofdm_tx              -- OFDM Transmit Signal Generation\n",
    "   ofdm_rx              -- OFDM Receive Signal Processing\n",
    "   mimo_ml              -- MIMO Maximum Likelihood (ML) Detection.\n",
    "   kbest                -- MIMO K-best Schnorr-Euchner Detection.\n",
    "   bit_lvl_repr         -- Bit level representation.\n",
    "   max_log_approx       -- Max-log approximation.\n",
    "\"\"\"\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange, array, zeros, pi, cos, sin, sqrt, log2, argmin, \\\n",
    "    hstack, repeat, tile, dot, shape, concatenate, exp, \\\n",
    "    log, vectorize, empty, eye, kron, inf\n",
    "from numpy.fft import fft, ifft\n",
    "from numpy.linalg import qr, norm\n",
    "\n",
    "from commpy.utilities import bitarray2dec, dec2bitarray\n",
    "\n",
    "__all__ = ['PSKModem', 'QAMModem', 'ofdm_tx', 'ofdm_rx', 'mimo_ml', 'kbest', 'bit_lvl_repr', 'max_log_approx']\n",
    "\n",
    "\n",
    "class Modem:\n",
    "    def modulate(self, input_bits):\n",
    "        \"\"\" Modulate (map) an array of bits to constellation symbols.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_bits : 1D ndarray of ints\n",
    "            Inputs bits to be modulated (mapped).\n",
    "        Returns\n",
    "        -------\n",
    "        baseband_symbols : 1D ndarray of complex floats\n",
    "            Modulated complex symbols.\n",
    "        \"\"\"\n",
    "        mapfunc = vectorize(lambda i:\n",
    "                            self.constellation[bitarray2dec(input_bits[i:i + self.num_bits_symbol])])\n",
    "\n",
    "        baseband_symbols = mapfunc(arange(0, len(input_bits), self.num_bits_symbol))\n",
    "\n",
    "        return baseband_symbols\n",
    "\n",
    "    def demodulate(self, input_symbols, demod_type, noise_var=0):\n",
    "        \"\"\" Demodulate (map) a set of constellation symbols to corresponding bits.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_symbols : 1D ndarray of complex floats\n",
    "            Input symbols to be demodulated.\n",
    "        demod_type : string\n",
    "            'hard' for hard decision output (bits)\n",
    "            'soft' for soft decision output (LLRs)\n",
    "        noise_var : float\n",
    "            AWGN variance. Needs to be specified only if demod_type is 'soft'\n",
    "        Returns\n",
    "        -------\n",
    "        demod_bits : 1D ndarray of ints\n",
    "            Corresponding demodulated bits.\n",
    "        \"\"\"\n",
    "        if demod_type == 'hard':\n",
    "            index_list = map(lambda i: argmin(abs(input_symbols[i] - self.constellation)),\n",
    "                             range(0, len(input_symbols)))\n",
    "            demod_bits = array([dec2bitarray(i, self.num_bits_symbol) for i in index_list]).reshape(-1)\n",
    "\n",
    "        elif demod_type == 'soft':\n",
    "            demod_bits = zeros(len(input_symbols) * self.num_bits_symbol)\n",
    "            for i in arange(len(input_symbols)):\n",
    "                current_symbol = input_symbols[i]\n",
    "                for bit_index in arange(self.num_bits_symbol):\n",
    "                    llr_num = 0\n",
    "                    llr_den = 0\n",
    "                    for const_index in self.symbol_mapping:\n",
    "                        if (const_index >> bit_index) & 1:\n",
    "                            llr_num = llr_num + exp(\n",
    "                                (-abs(current_symbol - self.constellation[const_index]) ** 2) / noise_var)\n",
    "                        else:\n",
    "                            llr_den = llr_den + exp(\n",
    "                                (-abs(current_symbol - self.constellation[const_index]) ** 2) / noise_var)\n",
    "                    demod_bits[i * self.num_bits_symbol + self.num_bits_symbol - 1 - bit_index] = log(llr_num / llr_den)\n",
    "        else:\n",
    "            raise ValueError('demod_type must be \"hard\" or \"soft\"')\n",
    "\n",
    "        return demod_bits\n",
    "\n",
    "    def plot_constellation(self):\n",
    "        \"\"\" Plot the constellation \"\"\"\n",
    "        # init some arrays\n",
    "        beta = self.num_bits_symbol\n",
    "        numbit = '0' + str(beta) + 'b'\n",
    "        Bin = []\n",
    "        mot = []\n",
    "        const = []\n",
    "\n",
    "        # creation of w array\n",
    "        reel = [pow(2, i) for i in range(beta // 2 - 1, -1, -1)]\n",
    "        im = [1j * pow(2, i) for i in range(beta // 2 - 1, -1, -1)]\n",
    "        w = concatenate((reel, im), axis=None)\n",
    "\n",
    "        listBin = [format(i, numbit) for i in range(2 ** beta)]\n",
    "        for e in listBin:\n",
    "            for i in range(beta):\n",
    "                Bin.append(ord(e[i]) - 48)\n",
    "                if ord(e[i]) - 48 == 0:\n",
    "                    mot.append(-1)\n",
    "                else:\n",
    "                    mot.append(1)\n",
    "            const.append(dot(w, mot))\n",
    "            mot = []\n",
    "        symb = self.modulate(Bin)\n",
    "\n",
    "        # plot the symbols\n",
    "        x = symb.real\n",
    "        y = symb.imag\n",
    "\n",
    "        plt.plot(x, y, '+', linewidth=4)\n",
    "        for i in range(len(x)):\n",
    "            plt.text(x[i], y[i], listBin[i])\n",
    "\n",
    "        plt.title('Constellation')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class PSKModem(Modem):\n",
    "    \"\"\" Creates a Phase Shift Keying (PSK) Modem object. \"\"\"\n",
    "\n",
    "    Es = 1\n",
    "\n",
    "    def _constellation_symbol(self, i):\n",
    "        return cos(2 * pi * (i - 1) / self.m) + sin(2 * pi * (i - 1) / self.m) * (0 + 1j)\n",
    "\n",
    "    def __init__(self, m):\n",
    "        \"\"\" Creates a Phase Shift Keying (PSK) Modem object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        m : int\n",
    "            Size of the PSK constellation.\n",
    "        \"\"\"\n",
    "        self.m = m\n",
    "        self.num_bits_symbol = int(log2(self.m))\n",
    "        self.symbol_mapping = arange(self.m)\n",
    "        self.constellation = list(map(self._constellation_symbol,\n",
    "                                      self.symbol_mapping))\n",
    "\n",
    "\n",
    "class QAMModem(Modem):\n",
    "    \"\"\" Creates a Quadrature Amplitude Modulation (QAM) Modem object.\"\"\"\n",
    "\n",
    "    def _constellation_symbol(self, i):\n",
    "        return (2 * i[0] - 1) + (2 * i[1] - 1) * (1j)\n",
    "\n",
    "    def __init__(self, m):\n",
    "        \"\"\" Creates a Quadrature Amplitude Modulation (QAM) Modem object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        m : int\n",
    "            Size of the QAM constellation.\n",
    "        \"\"\"\n",
    "\n",
    "        self.m = m\n",
    "        self.num_bits_symbol = int(log2(self.m))\n",
    "        self.symbol_mapping = arange(self.m)\n",
    "        mapping_array = arange(1, sqrt(self.m) + 1) - (sqrt(self.m) / 2)\n",
    "        self.constellation = list(map(self._constellation_symbol,\n",
    "                                      list(product(mapping_array, repeat=2))))\n",
    "        self.Es = 2 * (self.m - 1) / 3\n",
    "\n",
    "\n",
    "def ofdm_tx(x, nfft, nsc, cp_length):\n",
    "    \"\"\" OFDM Transmit signal generation \"\"\"\n",
    "\n",
    "    nfft = float(nfft)\n",
    "    nsc = float(nsc)\n",
    "    cp_length = float(cp_length)\n",
    "    ofdm_tx_signal = array([])\n",
    "\n",
    "    for i in range(0, shape(x)[1]):\n",
    "        symbols = x[:, i]\n",
    "        ofdm_sym_freq = zeros(nfft, dtype=complex)\n",
    "        ofdm_sym_freq[1:(nsc / 2) + 1] = symbols[nsc / 2:]\n",
    "        ofdm_sym_freq[-(nsc / 2):] = symbols[0:nsc / 2]\n",
    "        ofdm_sym_time = ifft(ofdm_sym_freq)\n",
    "        cp = ofdm_sym_time[-cp_length:]\n",
    "        ofdm_tx_signal = concatenate((ofdm_tx_signal, cp, ofdm_sym_time))\n",
    "\n",
    "    return ofdm_tx_signal\n",
    "\n",
    "\n",
    "def ofdm_rx(y, nfft, nsc, cp_length):\n",
    "    \"\"\" OFDM Receive Signal Processing \"\"\"\n",
    "\n",
    "    num_ofdm_symbols = int(len(y) / (nfft + cp_length))\n",
    "    x_hat = zeros([nsc, num_ofdm_symbols], dtype=complex)\n",
    "\n",
    "    for i in range(0, num_ofdm_symbols):\n",
    "        ofdm_symbol = y[i * nfft + (i + 1) * cp_length:(i + 1) * (nfft + cp_length)]\n",
    "        symbols_freq = fft(ofdm_symbol)\n",
    "        x_hat[:, i] = concatenate((symbols_freq[-nsc / 2:], symbols_freq[1:(nsc / 2) + 1]))\n",
    "\n",
    "    return x_hat\n",
    "\n",
    "\n",
    "def mimo_ml(y, h, constellation):\n",
    "    \"\"\" MIMO ML Detection.\n",
    "    parameters\n",
    "    ----------\n",
    "    y : 1D ndarray of complex floats\n",
    "        Received complex symbols (shape: num_receive_antennas x 1)\n",
    "    h : 2D ndarray of complex floats\n",
    "        Channel Matrix (shape: num_receive_antennas x num_transmit_antennas)\n",
    "    constellation : 1D ndarray of complex floats\n",
    "        Constellation used to modulate the symbols\n",
    "    \"\"\"\n",
    "    _, n = h.shape\n",
    "    m = len(constellation)\n",
    "    x_ideal = empty((n, pow(m, n)), complex)\n",
    "    for i in range(0, n):\n",
    "        x_ideal[i] = repeat(tile(constellation, pow(m, i)), pow(m, n - i - 1))\n",
    "    min_idx = argmin(norm(y[:, None] - dot(h, x_ideal), axis=0))\n",
    "    x_r = x_ideal[:, min_idx]\n",
    "\n",
    "    return x_r\n",
    "\n",
    "\n",
    "def kbest(y, h, constellation, K, noise_var=0, output_type='hard', demode=None):\n",
    "    \"\"\" MIMO K-best Schnorr-Euchner Detection.\n",
    "    Reference: Zhan Guo and P. Nilsson, 'Algorithm and implementation of the K-best sphere decoding for MIMO detection',\n",
    "        IEEE Journal on Selected Areas in Communications, vol. 24, no. 3, pp. 491-503, Mar. 2006.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : 1D ndarray\n",
    "        Received complex symbols (length: num_receive_antennas)\n",
    "    h : 2D ndarray\n",
    "        Channel Matrix (shape: num_receive_antennas x num_transmit_antennas)\n",
    "    constellation : 1D ndarray of floats\n",
    "        Constellation used to modulate the symbols\n",
    "    K : positive integer\n",
    "        Number of candidates kept at each step\n",
    "    noise_var : positive float\n",
    "        Noise variance.\n",
    "        *Default* value is 0.\n",
    "    output_type : str\n",
    "        'hard': hard output i.e. output is a binary word\n",
    "        'soft': soft output i.e. output is a vector of Log-Likelihood Ratios.\n",
    "        *Default* value is 'hard'\n",
    "    demode : function with prototype binary_word = demode(point)\n",
    "        Function that provide the binary word corresponding to a symbol vector.\n",
    "    Returns\n",
    "    -------\n",
    "    x : 1D ndarray of constellation points or of Log-Likelihood Ratios.\n",
    "        Detected vector (length: num_receive_antennas).\n",
    "    raises\n",
    "    ------\n",
    "    ValueError\n",
    "                If h has more columns than rows.\n",
    "                If output_type is something else than 'hard' or 'soft'\n",
    "    \"\"\"\n",
    "    nb_tx, nb_rx = h.shape\n",
    "    if nb_rx > nb_tx:\n",
    "        raise ValueError('h has more columns than rows')\n",
    "\n",
    "    # QR decomposition\n",
    "    q, r = qr(h)\n",
    "    yt = q.conj().T.dot(y)\n",
    "\n",
    "    # Initialization\n",
    "    m = len(constellation)\n",
    "    nb_can = 1\n",
    "\n",
    "    if isinstance(constellation[0], complex):\n",
    "        const_type = complex\n",
    "    else:\n",
    "        const_type = float\n",
    "    X = empty((nb_rx, K * m), dtype=const_type)  # Set of current candidates\n",
    "    d = tile(yt[:, None], (1, K * m))  # Corresponding distance vector\n",
    "    d_tot = zeros(K * m, dtype=float)  # Corresponding total distance\n",
    "    hyp = empty(K * m, dtype=const_type)  # Hypothesis vector\n",
    "\n",
    "    # Processing\n",
    "    for coor in range(nb_rx - 1, -1, -1):\n",
    "        nb_hyp = nb_can * m\n",
    "\n",
    "        # Copy best candidates m times\n",
    "        X[:, :nb_hyp] = tile(X[:, :nb_can], (1, m))\n",
    "        d[:, :nb_hyp] = tile(d[:, :nb_can], (1, m))\n",
    "        d_tot[:nb_hyp] = tile(d_tot[:nb_can], (1, m))\n",
    "\n",
    "        # Make hypothesis\n",
    "        hyp[:nb_hyp] = repeat(constellation, nb_can)\n",
    "        X[coor, :nb_hyp] = hyp[:nb_hyp]\n",
    "        d[coor, :nb_hyp] -= r[coor, coor] * hyp[:nb_hyp]\n",
    "        d_tot[:nb_hyp] += abs(d[coor, :nb_hyp]) ** 2\n",
    "\n",
    "        # Select best candidates\n",
    "        argsort = d_tot[:nb_hyp].argsort()\n",
    "        nb_can = min(nb_hyp, K)  # Update number of candidate\n",
    "\n",
    "        # Update accordingly\n",
    "        X[:, :nb_can] = X[:, argsort[:nb_can]]\n",
    "        d[:, :nb_can] = d[:, argsort[:nb_can]]\n",
    "        d[:coor, :nb_can] -= r[:coor, coor, None] * hyp[argsort[:nb_can]]\n",
    "        d_tot[:nb_can] = d_tot[argsort[:nb_can]]\n",
    "\n",
    "    if output_type == 'hard':\n",
    "        return X[:, 0]\n",
    "    elif output_type == 'soft':\n",
    "        return max_log_approx(y, h, noise_var, X[:, :nb_can], demode)\n",
    "    else:\n",
    "        raise ValueError('output_type must be \"hard\" or \"soft\"')\n",
    "\n",
    "\n",
    "def bit_lvl_repr(H, w):\n",
    "    \"\"\" Bit-level representation of matrix H with weights w.\n",
    "    parameters\n",
    "    ----------\n",
    "    H   :   2D ndarray (shape : nb_rx, nb_tx)\n",
    "            Channel Matrix.\n",
    "    w   :   1D ndarray of complex (length : beta)\n",
    "            Bit level representation weights. The length must be even.\n",
    "    return\n",
    "    ------\n",
    "    A : 2D nbarray (shape : nb_rx, nb_tx*beta)\n",
    "        Channel matrix adapted to the bit-level representation.\n",
    "    \"\"\"\n",
    "    beta = len(w)\n",
    "    if beta % 2 == 0:\n",
    "        m, n = H.shape\n",
    "        In = eye(n, n)\n",
    "        kr = kron(In, w)\n",
    "        return dot(H, kr)\n",
    "    else:\n",
    "        raise ValueError('Beta must be even.')\n",
    "\n",
    "\n",
    "def max_log_approx(y, h, noise_var, pts_list, demode):\n",
    "    \"\"\" Max-log demode\n",
    "    parameters\n",
    "    ----------\n",
    "    y : 1D ndarray\n",
    "        Received symbol vector (length: num_receive_antennas)\n",
    "    h : 2D ndarray\n",
    "        Channel Matrix (shape: num_receive_antennas x num_transmit_antennas)\n",
    "    noise_var : positive float\n",
    "        Noise variance\n",
    "    pts_list : 2D ndarray of constellation points\n",
    "        Set of points to compute max log approximation (points are column-wise).\n",
    "        (shape: num_receive_antennas x num_points)\n",
    "    demode : function with prototype binary_word = demode(point)\n",
    "        Function that provide the binary word corresponding to a symbol vector.\n",
    "    return\n",
    "    ------\n",
    "    LLR : 1D ndarray of floats\n",
    "        Log-Likelihood Ratio for each bit (same length as the return of decode)\n",
    "    \"\"\"\n",
    "    # Decode all pts\n",
    "    nb_pts = pts_list.shape[1]\n",
    "    bits = demode(pts_list.reshape(-1, order='F')).reshape(nb_pts, -1)  # Set of binary words (one word by row)\n",
    "\n",
    "    # Prepare LLR computation\n",
    "    nb_bits = bits.shape[1]\n",
    "    LLR = empty(nb_bits)\n",
    "\n",
    "    # Loop for each bit\n",
    "    for k in range(nb_bits):\n",
    "        # Select pts based on the k-th bit in the corresponding word\n",
    "        pts0 = pts_list.compress(bits[:, k] == 0, axis=1)\n",
    "        pts1 = pts_list.compress(bits[:, k] == 1, axis=1)\n",
    "\n",
    "        # Compute the norms and add inf to handle empty set of points\n",
    "        norms0 = hstack((norm(y[:, None] - h.dot(pts0), axis=0) ** 2, inf))\n",
    "        norms1 = hstack((norm(y[:, None] - h.dot(pts1), axis=0) ** 2, inf))\n",
    "\n",
    "        # Compute LLR\n",
    "        LLR[k] = min(norms0) - min(norms1)\n",
    "\n",
    "    return -LLR / (2 * noise_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note that the QAM soft-demodulators simply dont work due to a divide by zero error!'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qam4 = QAMModem(4)\n",
    "qam16 = QAMModem(16)\n",
    "qam64 = QAMModem(64)\n",
    "bpsk = PSKModem(2)\n",
    "psk8 = PSKModem(8)\n",
    "'''Note that the QAM soft-demodulators simply dont work due to a divide by zero error!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "def P_error_mqam(M, Es_No_Ratio, Es = None, No = None):\n",
    "    if Es != None and No != None:\n",
    "        return 2*(1-1/(np.sqrt(M)))*special.erfc(k*np.sqrt(Es/No))\n",
    "    else:\n",
    "        return 2*(1-1/(np.sqrt(M)))*special.erfc(k*np.sqrt(Es_No_Ratio))\n",
    "\n",
    "def P_error_mpsk(M, Es_No_Ratio, Es=None, No = None):\n",
    "    if Es != None and No != None:\n",
    "        return 2 * special.erfc(np.sqrt(2*(Es/No)*sin(np.pi/M)**2))\n",
    "    else:\n",
    "        return 2 * special.erfc(np.sqrt(2*(Es_No_Ratio)*sin(np.pi/M)**2))\n",
    "\n",
    "def P_error_bpsk(Es_No_Ratio, Es = None, No = None):\n",
    "    if Es != None and No != None:\n",
    "        return 0.5*special.erfc(np.sqrt(Es_No_Ratio))\n",
    "    else:\n",
    "        return 0.5*special.erfc(np.sqrt(Es/No))\n",
    "\n",
    "def calc_llr_wrong(symbol_mapping, r, s, h = np.complex64(1.0), No = 1, var = 1):\n",
    "    #https://arxiv.org/pdf/1903.04656.pdf\n",
    "    #I might be doing this wrong, this might supposed to be Probability(received symbol | bit of i = 1)\n",
    "    null_symbols = []\n",
    "    null_bits = []\n",
    "    my_symbol = []\n",
    "    my_bits = []\n",
    "    for key,value in symbol_mapping:\n",
    "        if s == key:\n",
    "            my_symbol.append(key)\n",
    "            my_bits.append(value)\n",
    "        else:\n",
    "            null_symbol.append(key)\n",
    "            null_symbol.append(value)\n",
    "            \n",
    "    a = np.exp(-1*(np.mag(r-h*my_symbol[0]))/var) #There is only one correct symbol\n",
    "    \n",
    "    running_sum = 0.0\n",
    "    for i in range(null_symbols):\n",
    "        b = np.exp(-1*(np.mag(r-h*null_symbols[i]))/var)\n",
    "        running_sum += b\n",
    "    \n",
    "def calc_llr_v0(symbol_mapping, r, s, h = np.complex64(1.0), No = 1, var = 1):\n",
    "    #https://arxiv.org/pdf/1903.04656.pdf\n",
    "    #I might be doing this wrong, this might supposed to be Probability(received symbol | bit of i = 1)\n",
    "    #s is the label, r is the received symbol\n",
    "    null_symbols = []\n",
    "    null_bits = []\n",
    "    my_symbol = []\n",
    "    my_bits = []\n",
    "    #print(symbol_mapping)\n",
    "    for key,value in symbol_mapping.items():\n",
    "        #print(\"for\", s, key)\n",
    "        if s == key:\n",
    "            my_symbol.append(key)\n",
    "            my_bits.append(value)\n",
    "        else:\n",
    "            null_symbols.append(key)\n",
    "            null_bits.append(value)\n",
    "    #print(my_bits)\n",
    "    run_sum_1 = 0.0\n",
    "    run_sum_0 = 0.0\n",
    "    for bit in my_bits[0]:\n",
    "        a = np.exp(-1*(np.linalg.norm(r-h*s))/var) #There is only one correct symbol\n",
    "        #print(a, bit)\n",
    "        if bit == '0':\n",
    "            run_sum_0 += a\n",
    "        else:\n",
    "            run_sum_1 += a\n",
    "    \n",
    "    Li = np.log2(run_sum_1) - np.log2(run_sum_0)\n",
    "    #If 0: Equally likely\n",
    "    #print(Li)\n",
    "    return Li\n",
    "\n",
    "def has_ith_bit(i = 0, bit = '0', symbol_mapping = {}):\n",
    "    sym_list = []\n",
    "    for symbol, bits in symbol_mapping.items():\n",
    "        if bits[i] == bit:\n",
    "            sym_list.append(symbol)\n",
    "    return sym_list\n",
    "\n",
    "def calc_llr(symbol_mapping, r, h = np.complex64(1.0), var = 1):\n",
    "    #https://arxiv.org/pdf/1903.04656.pdf\n",
    "    #I might be doing this wrong, this might supposed to be Probability(received symbol | bit of i = 1)\n",
    "    #s is the label, r is the received symbol\n",
    "    Ls = []\n",
    "    vals = list(symbol_mapping.values())\n",
    "    for i in range(len(vals[0])):\n",
    "        soft_symbols_1 = has_ith_bit(i = i, bit = '1', symbol_mapping = symbol_mapping)\n",
    "        soft_symbols_0 = has_ith_bit(i = i, bit = '0', symbol_mapping = symbol_mapping)\n",
    "        run_sum_1 = np.float64(0.0)\n",
    "        run_sum_0 = np.float64(0.0)\n",
    "        for local_s in soft_symbols_1:\n",
    "            a = np.exp(-1*(np.linalg.norm(r-h*local_s))/var) #Minimum is to fix growing exponential bug for each SNR\n",
    "            run_sum_1 += a\n",
    "        for local_s in soft_symbols_0:\n",
    "            a = np.exp(-1*(np.linalg.norm(r-h*local_s))/var) #Minimum is to fix growing exponential bug for each SNR\n",
    "            run_sum_0 += a\n",
    "        #print('runs1: ', run_sum_1, 'runs0: ', run_sum_0)\n",
    "        Li = np.float64(np.log2(run_sum_1)) - np.float64(np.log2(run_sum_0))\n",
    "        Ls.append(Li)\n",
    "    #print(Ls)\n",
    "    return Ls\n",
    "\n",
    "    \n",
    "def soft_demodulate(input_symbols, symbol_mapping, h = np.complex64(1.0), var = 1):\n",
    "    #Code taken from CommPy: https://github.com/veeresht/CommPy/blob/master/commpy/modulation.py\n",
    "    list_syms = np.array([ k for k in symbol_mapping.keys() ])\n",
    "    list_bits = np.array([ v for v in symbol_mapping.values() ])\n",
    "    str_out = ''\n",
    "    for i in range(len(input_symbols)):\n",
    "        llrs = calc_llr(symbol_mapping, input_symbols[i], h = h, var = var)\n",
    "        for llr in llrs:\n",
    "            if llr <= 0.0:\n",
    "                str_out += '0'\n",
    "            else:\n",
    "                str_out += '1'\n",
    "    return str_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModel(in_shape = 2, bps = 2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(in_shape, input_shape=(in_shape, )))\n",
    "    model.add(Dense(in_shape*64, input_shape=(in_shape, )))\n",
    "    #leakyrelu = keras.layers.LeakyReLU(alpha=0.3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(bps, input_shape=(bps, ), \n",
    "                   kernel_regularizer=regularizers.l2(0.0001)\n",
    "                    ,\n",
    "                    activity_regularizer=regularizers.l1(0.0001)))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def generateModelRNN(in_shape = 2, bps = 2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(5, input_shape=(in_shape, 1)))\n",
    "    model.add(Dense(bps))\n",
    "    model.add(Activation('relu'))\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00\n",
      "0000\n",
      "calc_llr: [-2.5457138269082145, -1.9682367243887073]\n",
      "calc_llr: [1.5940402850823552, 0.8192674455538647]\n",
      "calc_llr: [1.628907464555101, -0.6044061593021821]\n",
      "calc_llr: [1.1757619283683902, 0.1557260165832155, -0.17371323540141548, 0.1557260165832155]\n",
      "soft:  0000101010000010\n",
      "dict: {(-1-1j): '0000', (-0.33333334-1j): '0001', (0.33333334-1j): '0011', (1-1j): '0010', (-1-0.33333334j): '0110', (-0.33333334-0.33333334j): '0111', (0.33333334-0.33333334j): '0101', (1-0.33333334j): '0100', (-1+0.33333334j): '1100', (-0.33333334+0.33333334j): '1101', (0.33333334+0.33333334j): '1111', (1+0.33333334j): '1110', (-1+1j): '1010', (-0.33333334+1j): '1011', (0.33333334+1j): '1001', (1+1j): '1000'}\n"
     ]
    }
   ],
   "source": [
    "#Sanity Checking\n",
    "print(myqam4.dict[-1-1j])\n",
    "print(myqam16.dict[-1-1j])\n",
    "print('calc_llr:', calc_llr(myqam4.dict, -1-1j, h = 1.0))\n",
    "print('calc_llr:', calc_llr(myqam4.dict, -0.5+0.75j, h = 1.0))\n",
    "print('calc_llr:', calc_llr(myqam4.dict, -0.5+0.75j, h = 1.0 + 2j))\n",
    "print('calc_llr:', calc_llr(myqam16.dict, 0.75+0.75j, h = 1.0))\n",
    "print('soft: ', soft_demodulate([-1-1j, -1+1j, 1+1j, 1-1j], myqam16.dict, h=1.0))\n",
    "print('dict:', myqam16.dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1+0j): '0000', (0.9238795+0.38268343j): '0001', (0.70710677+0.70710677j): '0011', (0.38268343+0.9238795j): '0010', (6.123234e-17+1j): '0110', (-0.38268343+0.9238795j): '0111', (-0.70710677+0.70710677j): '0101', (-0.9238795+0.38268343j): '0100', (-1+1.2246469e-16j): '1100', (-0.9238795-0.38268343j): '1101', (-0.70710677-0.70710677j): '1111', (-0.38268343-0.9238795j): '1110', (-1.8369701e-16-1j): '1010', (0.38268343-0.9238795j): '1011', (0.70710677-0.70710677j): '1001', (0.9238795-0.38268343j): '1000'}\n",
      "calc_llr: [-0.45407425350371855, -1.6281609788657778, -0.6606638425187255, -0.19617467218996398]\n",
      "calc_llr: [0.45407425350371855, 1.6281609788657778, -0.6606638425187259, -0.19617467218996398]\n",
      "calc_llr: [-2.8853900817779268]\n",
      "calc_llr: [2.8853900817779268]\n",
      "soft:  001100\n",
      "dict: {(1+0j): '0', (-1+1.2246469e-16j): '1'}\n"
     ]
    }
   ],
   "source": [
    "#Sanity Checking\n",
    "print(myPSK8.dict)\n",
    "print('calc_llr:', calc_llr(myPSK8.dict, 1, h = 1.0))\n",
    "print('calc_llr:', calc_llr(myPSK8.dict, -1, h = 1.0))\n",
    "print('calc_llr:', calc_llr(myBPSK.dict, 1, h = 1.0))\n",
    "print('calc_llr:', calc_llr(myBPSK.dict, -1, h = 1.0))\n",
    "print('soft: ', soft_demodulate([1, 1, -1, -1, 1, 1], myBPSK.dict, h=1.0))\n",
    "print('dict:', myBPSK.dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise_variance: [0.010000000000000002]\n",
      "num_bits [4, 16, 64, 2, 8]\n"
     ]
    }
   ],
   "source": [
    "#Predefines for running LLR simulation\n",
    "#Generate randomized data now\n",
    "#Separate into training and test data\n",
    "%matplotlib inline\n",
    "from random import choice\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "RAND_DATA_CREATE = 64**2\n",
    "#RAND_DATA_CREATE = 8\n",
    "RAYLEIGH_FADING = np.complex64(1.0)\n",
    "#Signals have a max amplitude of 1.\n",
    "#SNR = Si - No #db\n",
    "#SNR = Si - sqrt(VAR)\n",
    "#VAR = (Si - SNR)**2. Assume Si = 1 (Most likely not the case)\n",
    "\n",
    "#SNR = Si/sqrt(VAR)\n",
    "#sqrt(VAR) = Si/SNR\n",
    "\n",
    "#SNRS = [-10, -5, -2, 1, 2, 3, 5, 10, 13, 15, 20]\n",
    "SNRS = [10]\n",
    "VARS = []\n",
    "VAR_RAYLEIGH = 1.0\n",
    "\n",
    "for snr in SNRS:\n",
    "    snr_linear = 10**(snr / 10)\n",
    "    VARS.append(np.float64(1/snr_linear)**2)\n",
    "\n",
    "print('noise_variance:' , VARS)\n",
    "    \n",
    "myModems = [myqam4, myqam16, myqam64, myBPSK, myPSK8]\n",
    "names = ['QAM', 'QAM16', 'QAM64', 'BPSK', 'PSK8']\n",
    "num_syms = [4,      16,     64,     2,        8]\n",
    "num_bits = [ k for k in (np.int_(num_syms)) ]\n",
    "history_list = []\n",
    "model_list = []\n",
    "data = ''.join(choice('01') for _ in range(RAND_DATA_CREATE))\n",
    "Adam=optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "#print('qam64dict: ', myqam64.dict)\n",
    "\n",
    "print('num_bits', num_bits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAM\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 128)               384       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 648\n",
      "Trainable params: 648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X\n",
      " [[-0.92284849 -1.06110928]\n",
      " [-1.1326511   0.96900305]\n",
      " [-1.066366   -1.08835489]\n",
      " ...\n",
      " [-0.92926077  1.06566084]\n",
      " [ 0.9301316  -1.02828217]\n",
      " [ 0.02244791 -0.08045234]] \n",
      "Y\n",
      " [[-1. -1.]\n",
      " [ 1.  1.]\n",
      " [-1. -1.]\n",
      " ...\n",
      " [ 1.  1.]\n",
      " [-1.  1.]\n",
      " [ 0.  0.]]\n",
      "X_train\n",
      " (1638, 2) \n",
      "Y_train\n",
      " (410, 2)\n",
      "X_test\n",
      " (410, 2) \n",
      "Y_test\n",
      " (410, 2)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-00ac52cb041f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mcnt_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mrun_simulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyModems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVARS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSNRS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-68-00ac52cb041f>\u001b[0m in \u001b[0;36mrun_simulation\u001b[1;34m(myModems, VARS, SNRS, names, optimizer)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mval_mselist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                 \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m                 \u001b[0mmselist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mval_mselist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    199\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                 \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[0;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.95\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[1;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[0;32m   3500\u001b[0m     \"\"\"\n\u001b[0;32m   3501\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[1;32m-> 3502\u001b[1;33m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[0;32m   3503\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[1;34m(a, func, **kwargs)\u001b[0m\n\u001b[0;32m   3408\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3410\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3411\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_median\u001b[1;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[0;32m   3533\u001b[0m             \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3534\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3535\u001b[1;33m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3537\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mpartition\u001b[1;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[0;32m    743\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"K\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#FeedForward Simulation\n",
    "def run_simulation(myModems, VARS, SNRS, names, optimizer=Adam):\n",
    "    cnt_index = 0\n",
    "    for modem in myModems:\n",
    "        for noise_var, snr in zip(VARS, SNRS):\n",
    "            print(names[cnt_index])\n",
    "            channel = rayleigh_multipath(noise_var, VAR_RAYLEIGH, [1.0, 0.7, 0.1, 0.3])\n",
    "            myModel = generateModel(bps = modem.bit_num)\n",
    "            #Process the data such that I'm sending an even number of bits through the modulator\n",
    "            if (names[cnt_index] != 'BPSK'):\n",
    "                length = len(data)\n",
    "                num_chunks = int(np.floor_divide(length, modem.bit_num))\n",
    "                proc_data = data[:length*num_chunks]\n",
    "            else:\n",
    "                proc_data = data\n",
    "            #print('proc_data',len(proc_data),' num_chunks: ', num_chunks)\n",
    "\n",
    "            #Add AWGN and Rayleigh fading through the channel\n",
    "            TX_data = modem.TX(proc_data)\n",
    "            X_pre = (channel.awgn(TX_data))\n",
    "            #X_pre = channel.apply_cir(X_pre)\n",
    "            X = []\n",
    "            TX = []\n",
    "            for x in X_pre:\n",
    "                X.append([x.real, x.imag])\n",
    "            for x in TX_data:\n",
    "                TX.append([x.real, x.imag])\n",
    "            X = np.array(X)\n",
    "            TX = np.array(TX)\n",
    "            y = []\n",
    "            #Calculate the labels (the LLRS) of the transmitted symbols [before any channels]\n",
    "            for symbol in TX:\n",
    "                complex_symbol = symbol[0] + 1j*symbol[1]\n",
    "                #Calculate the LLRs based off of the known approximate rayleigh and gaussian variances\n",
    "                ele = calc_llr(modem.dict, complex_symbol, h=VAR_RAYLEIGH, var = noise_var)\n",
    "                ele = np.tanh(ele)\n",
    "                y.append(ele)\n",
    "\n",
    "            y = np.array(y)\n",
    "            print('X\\n', X, '\\nY\\n', y)\n",
    "            #print('Xshape\\n', X.shape, '\\nYshape\\n', y.shape)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "            print('X_train\\n', X_train.shape, '\\nY_train\\n', y_test.shape)\n",
    "            print('X_test\\n', X_test.shape, '\\nY_test\\n', y_test.shape)\n",
    "            myModel.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error'])\n",
    "            epochs = 350\n",
    "            mselist = []\n",
    "            val_mselist = []\n",
    "            for i in range(epochs):\n",
    "                history=myModel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, verbose=False)\n",
    "                mselist.append(history.history['mean_squared_error'])\n",
    "                val_mselist.append(history.history['val_mean_squared_error'])\n",
    "            model_list.append(myModel)\n",
    "            fig = plt.figure()\n",
    "            ax = plt.gca()\n",
    "\n",
    "            ax.set_ylim(0, 1)\n",
    "            plt.plot(mselist)\n",
    "            plt.plot(val_mselist)\n",
    "            plt.title('Model Mean-Squared-Error %s SNR: %s' % (names[cnt_index], snr))\n",
    "            plt.ylabel('MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['MSE', 'Validation MSE'], loc = 'upper left')\n",
    "            plt.show()\n",
    "\n",
    "        cnt_index += 1\n",
    "\n",
    "run_simulation(myModems, VARS, SNRS, names, optimizer=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAM\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_18 (LSTM)               (None, 5)                 160       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 12        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 172\n",
      "Trainable params: 172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[-1.03639096-0.85299475j -1.10522355+1.14481202j -1.00066811-0.79159462j\n",
      " ... -1.15001618+1.13113545j  1.08565431-0.9404724j\n",
      " -0.09194923-0.10011722j]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\applications\\python3\\lib\\site-packages\\ipykernel_launcher.py:81: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      " [[-1.03639096 -0.85299475]\n",
      " [-1.10522355  1.14481202]\n",
      " [-1.00066811 -0.79159462]\n",
      " ...\n",
      " [-1.15001618  1.13113545]\n",
      " [ 1.08565431 -0.9404724 ]\n",
      " [-0.09194923 -0.10011722]] \n",
      "Y\n",
      " [[-1. -1.]\n",
      " [ 1.  1.]\n",
      " [-1. -1.]\n",
      " ...\n",
      " [ 1.  1.]\n",
      " [-1.  1.]\n",
      " [ 0.  0.]]\n",
      "Xshape\n",
      " (2048, 2) \n",
      "Yshape\n",
      " (2048, 2)\n",
      "X_train\n",
      " (1638, 2, 1) \n",
      "Y_train\n",
      " (410, 2)\n",
      "X_test\n",
      " (410, 2, 1) \n",
      "Y_test\n",
      " (410, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_18_input to have shape (1, 2) but got array with shape (2, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-c7952ae23e25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mcnt_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mrun_simulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyModems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVARS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSNRS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-75-c7952ae23e25>\u001b[0m in \u001b[0;36mrun_simulation\u001b[1;34m(myModems, VARS, SNRS, names, optimizer)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mval_mselist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                 \u001b[0mmselist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[0mval_mselist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_mean_squared_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_18_input to have shape (1, 2) but got array with shape (2, 1)"
     ]
    }
   ],
   "source": [
    "#RNN Simulation\n",
    "def run_simulation(myModems, VARS, SNRS, names, optimizer=Adam):\n",
    "    cnt_index = 0\n",
    "    for modem in myModems:\n",
    "        for noise_var, snr in zip(VARS, SNRS):\n",
    "            print(names[cnt_index])\n",
    "            channel = rayleigh_multipath(noise_var, VAR_RAYLEIGH, [-2.5, 0, 1.0, 1.5])\n",
    "            myModel = generateModelRNN(bps = modem.bit_num)\n",
    "            #Process the data such that I'm sending an even number of bits through the modulator\n",
    "            if (names[cnt_index] != 'BPSK'):\n",
    "                length = len(data)\n",
    "                num_chunks = int(np.floor_divide(length, modem.bit_num))\n",
    "                proc_data = data[:length*num_chunks]\n",
    "            else:\n",
    "                proc_data = data\n",
    "            #print('proc_data',len(proc_data),' num_chunks: ', num_chunks)\n",
    "\n",
    "            #Add AWGN and Rayleigh fading through the channel\n",
    "            TX_data = modem.TX(proc_data)\n",
    "            #X_pre = (channel.awgn(TX_data))\n",
    "            X_pre = channel.apply_cir(TX_data)[:len(TX_data)]\n",
    "            X_pre = (channel.awgn(TX_data))\n",
    "            print(X_pre)\n",
    "            X = []\n",
    "            TX = []\n",
    "            for x in X_pre:\n",
    "                X.append([x.real, x.imag])\n",
    "            for x in TX_data:\n",
    "                TX.append([x.real, x.imag])\n",
    "            X = np.array(X)\n",
    "            TX = np.array(TX)\n",
    "            y = []\n",
    "            \n",
    "            #Calculate the labels (the LLRS) of the transmitted symbols [before any channels]\n",
    "            for symbol in TX:\n",
    "                complex_symbol = symbol[0] + 1j*symbol[1]\n",
    "                #Calculate the LLRs based off of the known approximate rayleigh and gaussian variances\n",
    "                ele = calc_llr(modem.dict, complex_symbol, h=VAR_RAYLEIGH, var = noise_var)\n",
    "                ele = np.tanh(ele)\n",
    "                y.append(ele)\n",
    "\n",
    "            y = np.array(y)\n",
    "            print('X\\n', X, '\\nY\\n', y)\n",
    "            print('Xshape\\n', X.shape, '\\nYshape\\n', y.shape)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "            X_train = np.expand_dims(X_train, -1)\n",
    "            X_test = np.expand_dims(X_test, -1)\n",
    "            print('X_train\\n', X_train.shape, '\\nY_train\\n', y_test.shape)\n",
    "            print('X_test\\n', X_test.shape, '\\nY_test\\n', y_test.shape)\n",
    "            #print('X_train\\n', X_train, '\\nY_train\\n', y_test)\n",
    "            #print('X_test\\n', X_test, '\\nY_test\\n', y_test)\n",
    "            myModel.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error'])\n",
    "            epochs = 350\n",
    "            mselist = []\n",
    "            val_mselist = []\n",
    "            for i in range(epochs):\n",
    "                history=myModel.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1, verbose=False)\n",
    "                mselist.append(history.history['mean_squared_error'])\n",
    "                val_mselist.append(history.history['val_mean_squared_error'])\n",
    "            model_list.append(myModel)\n",
    "            fig = plt.figure()\n",
    "            ax = plt.gca()\n",
    "\n",
    "            ax.set_ylim(0, 1)\n",
    "            plt.plot(mselist)\n",
    "            plt.plot(val_mselist)\n",
    "            plt.title('Model Mean-Squared-Error %s SNR: %s' % (names[cnt_index], snr))\n",
    "            plt.ylabel('MSE')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.legend(['MSE', 'Validation MSE'], loc = 'upper left')\n",
    "            plt.show()\n",
    "\n",
    "        cnt_index += 1\n",
    "\n",
    "run_simulation(myModems, VARS, SNRS, names, optimizer=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debug BPSK\n",
    "\n",
    "#BPSK_model = model_list[3]\n",
    "print('BPSK negative:' , BPSK_model.predict(np.array([[-9.0, 0.0]])))\n",
    "print('BPSK positive:' , BPSK_model.predict(np.array([[1.0, 0.0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "use_mse = True\n",
    "\n",
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    '''\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 100\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-1, 1, n)\n",
    "    grid_y = np.linspace(-1, 1, n)[::-1]\n",
    "    x_decoded_list = []\n",
    "    y_decoded_list = []\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            x_decoded_list.append(x_decoded[0][0])\n",
    "            y_decoded_list.append(x_decoded[0][1])\n",
    "\n",
    "    print('x:', x_decoded_list, '\\ny:', y_decoded_list)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_xlim(-1, 1)\n",
    "    plt.xlabel(\"Real\")\n",
    "    plt.ylabel(\"Imag\")\n",
    "    plt.scatter(x_decoded_list, y_decoded_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "\n",
    "def run_vae_sim(X_train, X_test, original_dim, intermediate_dim, batch_size, latent_dim, epochs, use_mse=True, name = \"\", snr = \"\"):\n",
    "    # network parameters\n",
    "    input_shape = (original_dim, )\n",
    "\n",
    "    print('input_shape', input_shape)\n",
    "    \n",
    "    # VAE model = encoder + decoder\n",
    "    # build encoder model\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    print('input_shape', input_shape)\n",
    "    x = Dense(intermediate_dim, activation='sigmoid')(inputs)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    # instantiate encoder model\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    #encoder.summary()\n",
    "    plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)\n",
    "\n",
    "    # build decoder model\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='sigmoid')(latent_inputs)\n",
    "    outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "    # instantiate decoder model\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    #decoder.summary()\n",
    "    plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)\n",
    "\n",
    "    # instantiate VAE model\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    #vae = Model(inputs, outputs, name='vae_mlp')\n",
    "    vae = Model(inputs, outputs)\n",
    "    vae2 = Model(inputs,outputs)\n",
    "    # VAE loss = mse_loss or xent_loss + kl_loss\n",
    "    if use_mse:\n",
    "        reconstruction_loss = mse(inputs, outputs)\n",
    "    else:\n",
    "        reconstruction_loss = binary_crossentropy(inputs,\n",
    "                                                  outputs)\n",
    "    models = (encoder,decoder)\n",
    "    data = (X_test, X_test)\n",
    "    reconstruction_loss *= original_dim\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "    vae.add_loss(vae_loss)\n",
    "    vae.compile(optimizer=Adam, metrics=['mse', 'mean_squared_error'])\n",
    "    #vae.metrics_tensors.append(mse(inputs, outputs, input_dim))\n",
    "    #vae.metrics_names.append(\"mse\")\n",
    "    #We don't actually train the vae2 model; vae2 shares the same weights and biases\n",
    "    #So we only evaluate our metrics to avoid a keras bug: https://github.com/keras-team/keras/issues/9459\n",
    "    \n",
    "    vae2.compile(optimizer=Adam, loss = 'mean_squared_error', metrics=['mse'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    vae.summary()\n",
    "    \n",
    "    plot_model(vae,\n",
    "               to_file='vae_mlp.png',\n",
    "               show_shapes=True)\n",
    "    val_mse_list = []\n",
    "    mse_list = []\n",
    "    for i in range(epochs):\n",
    "        history_dontuse = vae.fit(X_train,\n",
    "                epochs=1,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=(X_test, None)\n",
    "                ,verbose = False)\n",
    "        \n",
    "        val_mse_list.append(vae2.evaluate(X_test, X_test, verbose=False)[1])\n",
    "        mse_list.append(vae2.evaluate(X_train, X_train,verbose=False)[1])\n",
    "        \n",
    "        #vae.save_weights('vae_mlp_mnist.h5')\n",
    "    \n",
    "    #print('val_mse_list', val_mse_list)\n",
    "    #print('mse_list', mse_list)\n",
    "    plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=batch_size)\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.set_ylim(0, 3)\n",
    "    #print('history:', history.history.keys())\n",
    "    plt.plot(mse_list)\n",
    "    plt.plot(val_mse_list)\n",
    "    plt.title('Model Mean-Squared-Error Modulation: %s SNR: %s' % (name, snr))\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['MSE', 'Validation MSE'], loc = 'upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    '''\n",
    "    plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=batch_size,\n",
    "                 model_name=\"vae_mlp\")\n",
    "    '''\n",
    "    '''\n",
    "def plot():\n",
    "    def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    \n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "'''\n",
    "#do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process data similar to forward-connected example.\n",
    "\n",
    "def run_simulation_vae(myModems, VARS, SNRS, names, optimizer='Adam'):\n",
    "    return_list = []\n",
    "    cnt_index = 0\n",
    "    for modem in myModems:\n",
    "        for noise_var, snr in zip(VARS, SNRS):\n",
    "            print(names[cnt_index])\n",
    "            channel = rayleigh_multipath(noise_var, VAR_RAYLEIGH, [1.0, 0.7, 0.1, 0.3])\n",
    "            myModel = generateModel(bps = modem.bit_num)\n",
    "            #Process the data such that I'm sending an even number of bits through the modulator\n",
    "            if (names[cnt_index] != 'BPSK'):\n",
    "                length = len(data)\n",
    "                num_chunks = int(np.floor_divide(length, modem.bit_num))\n",
    "                proc_data = data[:length*num_chunks]\n",
    "            else:\n",
    "                proc_data = data\n",
    "            #print('proc_data',len(proc_data),' num_chunks: ', num_chunks)\n",
    "            \n",
    "            #Add AWGN and Rayleigh fading through the channel\n",
    "            \n",
    "            TX_data = modem.TX(proc_data)\n",
    "            #print('RX Test: ', modem.RX(TX_data))\n",
    "            X_pre = (channel.awgn(TX_data))\n",
    "            #X_pre = channel.apply_cir(X_pre)\n",
    "            X = []\n",
    "            TX = []\n",
    "            for x in X_pre:\n",
    "                X.append([x.real, x.imag])\n",
    "            for x in TX_data:\n",
    "                TX.append([x.real, x.imag])\n",
    "            X = np.array(X)\n",
    "            TX = np.array(TX)\n",
    "            y = []\n",
    "            #Calculate the labels (the LLRS) of the transmitted symbols [before any channels]\n",
    "            for symbol in TX:\n",
    "                complex_symbol = symbol[0] + 1j*symbol[1]\n",
    "                #Calculate the LLRs based off of the known approximate rayleigh and gaussian variances\n",
    "                ele = calc_llr(modem.dict, complex_symbol, h=VAR_RAYLEIGH, var = noise_var)\n",
    "                ele = np.tanh(ele)\n",
    "                y.append(ele)\n",
    "\n",
    "            y = np.array(y)\n",
    "            print('X\\n', X, '\\nY\\n', y)\n",
    "            #print('Xshape\\n', X.shape, '\\nY.shape\\n', y.shape)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "            print('Xtrainshape\\n', X_train.shape, '\\nYtrain.shape\\n', y_train.shape)\n",
    "            print('Xtestshape\\n', X_test.shape, '\\nYtest.shape\\n', y_test.shape)\n",
    "            #Train VAE\n",
    "            #X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
    "            #X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
    "            #print('input_dim: ', input_dim)\n",
    "            #vae, encoder, generator, loss = generate_model_vae(input_dim, input_dim, input_dim, batch_size, use_mse = True, optimizer = 'RMSProp')\n",
    "            batch_size = 100\n",
    "            epochs = 100\n",
    "            #                                           in  out             latent\n",
    "            run_vae_sim(X_train, X_test, 2, 2, batch_size, y.shape[1], epochs, use_mse=False, name = names[cnt_index], snr = snr)\n",
    "            cnt_index += 1\n",
    "    \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAM\n",
      "X\n",
      " [[-0.80232696 -0.93133374]\n",
      " [-1.08557893  0.96619658]\n",
      " [-0.89353023  0.98739001]\n",
      " ...\n",
      " [-0.97725982  0.96284575]\n",
      " [-0.85872621  0.97528182]\n",
      " [-0.12560638 -0.18951513]] \n",
      "Y\n",
      " [[-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " ...\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]\n",
      " [ 0.  0.]]\n",
      "Xtrainshape\n",
      " (1638, 2) \n",
      "Ytrain.shape\n",
      " (1638, 2)\n",
      "Xtestshape\n",
      " (410, 2) \n",
      "Ytest.shape\n",
      " (410, 2)\n",
      "input_shape (2,)\n",
      "input_shape (2,)\n",
      "Model: \"model_123\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              [(None, 2), (None, 2), (N 18        \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 2)                 12        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-3ddd33f7f4a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#X_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#X_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrun_simulation_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyModems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVARS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSNRS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-170-d62aed245d5b>\u001b[0m in \u001b[0;36mrun_simulation_vae\u001b[1;34m(myModems, VARS, SNRS, names, optimizer)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m#                                           in  out             latent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0mrun_vae_sim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_mse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcnt_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msnr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msnr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mcnt_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-167-012895369e4d>\u001b[0m in \u001b[0;36mrun_vae_sim\u001b[1;34m(X_train, X_test, original_dim, intermediate_dim, batch_size, latent_dim, epochs, use_mse, name, snr)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mval_mse_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvae2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mmse_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvae2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m#vae.save_weights('vae_mlp_mnist.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1359\u001b[0m                                          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                          \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m                                          callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \"\"\"\n\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m     num_samples = check_num_samples(ins,\n\u001b[0;32m    370\u001b[0m                                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_trainable_weights_consistency\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \"\"\"\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2958\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m     \"\"\"\n\u001b[1;32m-> 2960\u001b[1;33m     \u001b[0mtf_keras_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2962\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3341\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3342\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3343\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3344\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3345\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    814\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[1;32m--> 816\u001b[1;33m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[0;32m    817\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\python3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, name)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;34m\"AssignVariableOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         value)\n\u001b[0m\u001b[0;32m    180\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#X_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "#X_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "run_simulation_vae(myModems, VARS, SNRS, names, optimizer=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
